---
title: 回归常用评价指标
mathjax: true
date: 2020-01-24 22:06:14
tags:
- 算法
categories:
- 学习
- 算法
- ML
---
回归算法常用的评价指标：MSE，RMSE，MAE、R-Squared。
<!--more-->
# 均方误差（MES：Mean Squared Error）  
$$ \frac{1}{m} \sum_{i=1}^{m} ({y_i}-\hat{y_i})^2$$  
使用测试集上的值（真实值$y_i$）-预测值（$\hat{y_i}$），之后平方再取平均，经常会用在线性回归上做损失函数，因为他直接表示了预测值和真实值的误差大小，所以很适合来评估线性回归模型的准确度。  
# 均方根误差（RMSE：Root Mean Squard Error）
## 本体
$$ \sqrt{ \frac{1}{m} \sum_{i=1}^{m} ({y_i}-\hat{y_i})^2 }$$  
MES开根号就是RMSE，但是为什莫要这么做呢？？？  
为了让数据更好描述，为了输入和输出的数量级在同一个量级上，这样就可以直接在描述模型的时候说模型的误差是多少。  
## 标准差（Standard Deviation）  
标准差是方差的算术平方根，也称均方差（mean square error），是各数据偏离平均数的距离的平均数，它是离均差平方和平均后的方根，用σ表示，标准差能反映一个数据集的离散程度。  
$$
\begin{aligned}
    S^2 &= \frac{1}{n} \sum_{i=1} ({x_i - \overline{X}}) ^2   \qquad \text{总体方差Var}  \\\\
    \sigma &= \sqrt{\frac{1}{n} \sum_{i=1}^N (x_i - \mu)^2 }  \qquad \text{总体标准差SD}
\end{aligned}
$$

公式本体很像，SD更多应该是在统计中使用，均方根误差有的地方又叫标准误差（和标准差就差一个字，我人都傻了）更多是表征回归模型的结果，***这个在下边拟合度R的计算中会体现出来***。  
统计中经常又不能对整个集合进行统计，所以又会有样本方差，和总体方差又不一样，他将分母换成了n-1，这个不再细说。
# 平均绝对误差（MAE）
$$  \frac{1}{m} \sum_{i=1}^{m} |{y_i}-\hat{y_i}|$$
# 拟合度R平方（R Squared）
## 概念
线性回归问题中，R-Squared 是用来衡量回归方程与真实样本输出之间的相似程度。  

在上边描述的几种评价指标中，根据不同的问题，可能会有不一样的结果。比如预测股票，每股价格误差结果可能是几十，预测人口增长误差结果可能是上万。那么如果有一个统一的评价标准来描述就可以很直观的对模型的准确性有一个认识，这时候就出现了拟合度R方这个东西，**相当于一个归一化的过程**。  

$$ 
\begin{aligned}
    R^2 = 1 - \frac{SS_{residual}}{SS_{total}}
\end{aligned} 
$$  

其中分子是Residual Sum of Squares 分母是 Total Sum of Squares  
$$ \begin{aligned}
    SS_{residual} &= \sum_i {(y_i - \hat{y}_i)^2}  \\\\
    \quad SS_t &= \sum_i {(y_i - \overline{y}_i)^2}
\end{aligned}$$

由以上各式很明显可以明白。  

分子是使用模型计算得到的误差，真实值与预测值的平方差之和，类似于均方差MSE。  
分母是没有任何模型，按照平均值计算得到的误差（相当于瞎猜的结果），真实值与均值的平方差之和，类似于方差 Var（也叫偏估计）。  
其实，上下同除n，就会发现分子变成了MSE，分母变成了Var。  
## 性质
根据 R-Squared 的取值，来判断模型的好坏：如果结果是 0，说明模型拟合效果很差；如果结果是 1，说明模型无错误。一般来说，R-Squared 越大，表示模型拟合效果越好。  
R-Squared 反映的是大概有多准，因为，随着样本数量的增加，R-Square必然增加，无法真正定量说明准确程度，只能大概定量。

# 协方差（Covariance）
协方差在概率论和统计学中用于衡量两个变量的总体误差。而方差是协方差的一种特殊情况。  
如果两个变量的变化趋势一致，也就是说如果其中一个大于自身的期望值，另外一个也大于自身的期望值，那么两个变量之间的协方差就是正值，反之为负值，所以他表征了两个变量的总体误差。  
$$
{cov(X,Y)} = \frac{ \sum_{i=1}^n  ( X_i - \overline{X} ) ( Y_i - \overline{Y} ) }{n-1}
$$

# 代码
scikit-learn中集成了很多工具，上边叙述的基本都可以直接调用方法实现。
```python
from sklearn.metrics import mean_squared_error #均方误差
from sklearn.metrics import mean_absolute_error #平方绝对误差
from sklearn.metrics import r2_score#R square
#调用
mean_squared_error(y_test,y_predict)
mean_absolute_error(y_test,y_predict)
r2_score(y_test,y_predict)
```
# 参考
[均方根值、均方根误差以及标准差](https://blog.csdn.net/charlene_bo/article/details/70599183)  
[R-Squared](https://blog.csdn.net/zrh_CSDN/article/details/81190001)