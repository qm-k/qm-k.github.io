---
title: NCHW与NHWC
date: 2019-10-14 14:30:03
tags:
categories:
- 学习
- 算法
---
在使用NPU的过程中会遇到要将npu输出的一维数据重新`reshape`成正常的表示图像大小、通道数、以及图片数量的数据格式，这时候有两种常用的顺序可以使用`NCHW`、`NHWC`。  
<!--more-->
| N | 一个batch内图片的数量 |
| :----: | :----: |
| C | 通道数channel。例如灰度图像为1， 彩色RGB图像为3 |
| H | 垂直高度方向的像素个数 |
| W | 水平宽度方向的像素个数 |

# 改变维度顺序
例如现在有一个张量如下:
```
x = [[[  1,   2],
      [  3,   4]],
     [[ 5,  6],
      [ 7,  8]],
     [[9, 10,
      [11, 12]]]
```
此时他的shape即为（3，2，2），可以通过`x[0,:,:]`将第一个维度的值输出出来
```
>>> x[0, :, :]
<tf.Tensor: id=7, shape=(2, 2), dtype=int32, numpy=
array([[1, 2],
       [3, 4]], dtype=int32)>
```
为什莫要讨论其中某一个维度的位置呢？这个会在下边两种存储方式优劣的对比上体现出来，主要会在访存上体现出差别。  

如果需要切换通道顺序可以使用`tf.transpose`如果是numpy变量可以使用`np.transpose`  
```
y = tf.transpose(x, [1, 2, 0]) #第一个是参数要切换顺序的张量，第二个参数是改变后的通道顺序  
#数字是原始张量中的维度编号，如原来的第一维0维现在是最后一维
```
# 将输出的一维结果转换为所需维度
各种加速棒或者npu、kpu计算的结果是一维的张量，需要将结果转化为正常的维度才能使用  
```
output = output.reshape(1, 57, 46, 46)
```
比如使用RK的1808NPU进行加速：
```
    frame = cv2.resize(frame, (inWidth, inHeight), interpolation=cv2.INTER_CUBIC)
    if not hasFrame:
        cv2.waitKey()
        break
    frameWidth = frame.shape[1]
    frameHeight = frame.shape[0]

    # input mode转为’nchw’
    frame_input = np.transpose(frame, [2, 0, 1])
    t = time.time()
    [output] = rknn.inference(inputs=[frame_input], data_format="nchw")
    print("time:", time.time()-t)
   
    # rknn输出的数组转为1x57x46x46的矩阵
    output = output.reshape(1, 57, 46, 46)
```
# 两种存储方式的优劣对比  

{%asset_img all.png%}  
由于数据存储是按张量最深层的维度进行依次遍历的就像下图这样存储：
{%asset_img diff.png%}  

**在NCHW的存储方式下，每一张图片都由W通道开始存储，也就是从一行的最左端存储到最右端，之后H通道加1，存储下一行，直到整个R通道存储完毕，通道数加1，存储G通道，一直存储到这张图片结束（为了方便，每一个通道我都只画了2x2个像素），而NHWC则先遍历存储通道，将一个图片坐标下的RGB通道遍历存储完之后再存储下一个坐标上的三个通道，两种存储方式都是最后再遍历一个batch内的图片张数（将前一张全部存储完毕后存储下一张）。** 

深度学习中涉及大量的数据计算,计算需要从内存中取出数据,因此需要计算出数据的偏移地址以便进行取数。  

那么根据以上分析，可以定义位置(n,c,h,w)表示第n个batch的第c通道的第h行的第w列,那么该位置在不同数据格式下,在内存中的偏移地址计算公式如下:  
NCHW: offset_nchw(n, c, h, w) = n * CHW + c * HW + h * W + w  
NHWC: offset_nhwc(n, c, h, w) = n * HWC + h * WC + w * C + c  
CHWN: offset_chwn(n, c, h, w) = c * HWN + h * WN + w * N + n  

其中N、C、H、W为常量表示各个通道的最大值,n、c、h、w为变量表示当前位置的高维坐标。  

在NCHW中,CHW=C\*H\*W,表示一个Batch,可以理解成一个BGR 3通道的图片,表达的是一个立方体。HW=H\*W,表示一个平面,可以理解成是BGR3通道图片的一个通道(灰度图就是一个通道图片)。W是一行,可以理解成一个通道上的一行。  
{%asset_img toggle_movement.gif%}  
结合上边加粗部分的论述和上图卷积过程的特点，两种计算方式的过程如下：  

先通道后像素:先把一个像素点的所有通道数与卷积的参数相乘后累加,再进行下一个像素,直到卷积核窗口乘累加完成。比如第一次滑窗的计算公式  
(w0,0,0)\*(x0,0,0) + (w1,0,0)\*(x1,0,0) + (w2,0,0)\*(x2,0,0) + (w0,0,1)\*(x0,0,1) + (w1,0,1)\*(x1,0,1) + (w2,0,1)\*(x2,0,1) + (w0,0,2)\*(x0,0,2) + (w1,0,1)\*(x1,0,2) + (w2,0,2)\*(x2,0,2) + (w0,1,0)\*(x0,1,0) + (w1,1,0)\*(x1,1,0) + (w2,1,0)\*(x2,1,0) + (w0,1,1)\*(x0,1,1) + (w1,1,1)\*(x1,1,1) + (w2,1,1)\*(x2,1,1) + (w0,1,2)\*(x0,1,2) + (w1,1,1)\*(x1,1,2) + (w2,1,2)\*(x2,1,2) + (w0,2,0)\*(x0,2,0) + (w1,2,0)\*(x1,2,0) + (w2,2,0)\*(x2,2,0) + (w0,2,1)\*(x0,2,1) + (w1,2,1)\*(x1,2,1) + (w2,2,1)\*(x2,2,1) + (w0,2,2)\*(x0,2,2) + (w1,2,1)\*(x1,2,2) + (w2,2,2)\*(x2,2,2) = 0\*-1 + 0\*-1 + 0\*0 + 0\*1 + 0\*-1 + 0\*0 + 0\*0 + 0\*0 + 0\*-1 + 0\*0 + 0\*0 + 0\*0 + 0\*1 + 1\*0 + 2\*1 + 1\*0 + 0\*0 +1\*0 + 0\*0 + 0\*0 + 0\*1 + 2\*1 + 0\*-1 + 1\*-1 + 2\*1 + 0\*0 + 0\*-1 = 5

　　先像素后通道:先把一个通道滑动窗口与卷积参数相乘后累加,再进行下一个通道,直到所有通道乘累加完成。比如第一次滑窗计算公式  
(w0,0,0)\*(x0,0,0) + (w0,0,1)\*(x0,0,1) + (w0,0,2)\*(x0,0,2) + (w0,1,0)\*(x0,1,0) + (w0,1,1)\*(x0,1,1) + (w0,0,2)\*(x0,1,2) + (w0,2,0)\*(x0,2,0) + (w0,0,1)\*(x0,2,1) + (w0,0,2)\*(x0,2,2) + (w1,0,0)\*(x1,0,0) + (w1,0,1)\*(x1,0,1) + (w1,0,2)\*(x1,0,2) + (w1,1,0)\*(x1,1,0) + (w1,1,1)\*(x1,1,1) + (w1,0,2)\*(x1,1,2) + (w1,2,0)\*(x1,2,0) + (w1,0,1)\*(x1,2,1) + (w1,0,2)\*(x1,2,2) + (w2,0,0)\*(x2,0,0) + (w2,0,1)\*(x2,0,1) + (w2,0,2)\*(x2,0,2) + (w2,1,0)\*(x2,1,0) + (w2,1,1)\*(x2,1,1) + (w2,0,2)\*(x2,1,2) + (w2,2,0)\*(x2,2,0) + (w2,0,1)\*(x2,2,1) + (w2,0,2)\*(x2,2,2) = 0\*-1 + 0\*1 + 0\*0 + 0\*0 +0\*1 + 1\*0 + 0\*0 + 2\*1 + 2\*1 + 0\*-1 + 0\*-1 + 0\*0 + 0\*0 + 1\*0 + 0\*0 + 0\*0 + 0\*-1 + 0\*0 + 0\*0 + 0\*0 + 0\*-1 + 0\*0 + 2\*1 + 1\*0 + 0\*1 + 1\*-1 + 0\*-1 = 5  

两种计算的结果并没有差别，但是在存取次数上就有了明显的差别了。  
对于NHWC格式,即先通道后像素,是把一个像素的所有通道的数据放在一起。这样对应上图第一个像素的3个通道值,第二个像素的3个通道值,第三个像素的3个通道值,它们在内存中的地址都是连续的,也就是说一次就可以把kernel第一行需要计算的数取出,3x3的kernel需要3次取数。

　　而对于NCHW格式,即先像素后通道,是把一个通道的所有像素按顺序排列,这样对于一个3*3的卷积核,需要每取3个数就需要跳跃n个数后,再取3个数。一个通道需要取3次,3个通道需要取9次。  
在实际网络中,通常通道数会远大于卷积kernel数(不会像上图只有3个通道,通常是几十、几百个通道)。这样对于NHWC格式来说说,取数的次数会比NCHW少很多。  

同时在做图像的灰度化的过程中也是同样的道理，由于NHWC的同一坐标下像素是在内存中连续存储的，所以NHWC的访存局部性更好（每三个输入像素即可得到一个输出像素），NCHW 则必须等所有通道全部读取完毕才能得到最终输出结果，需要占用较大的临时空间。  
{%asset_img NHWC.png%}  
# 存储格式在不同设备上的区别
但是由于CPU是基于延迟优化的，而GPU是基于带宽优化的，所以，在不同的设备上两种存储方式各有优势，虽然NCHW格式需要更大的内存更多的存取次数，但是在GPU这种具有大量流处理器、高带宽的设备上高内存操作复杂度、多次重复的简单运算就会具有很大的优势，一般好的CPU大约能达到50GB/s的内存带宽，而好的GPU能达到750GB/s的内存带宽，CPU更擅长的是快速获取少量的内存，这时候NHWC就显得有优势。  
早期的tensorflow采用NHWC格式就是因为早期的开发多数是基于CPU的，cache的利用效率更高，之后GPU高速发展之后NCHW格式就开始大规模使用，像常用的Nvidia cuDNN就是默认使用NCHW格式进行读写的。  
参考：
[AIBOOM的blog](https://www.cnblogs.com/AIBOOM/p/11497507.html)
[RLilyX的blog](https://blog.csdn.net/weixin_37801695/article/details/86614566)